1. 全新数据集上预测准确率、召回率很低很低！ 但是在原来的训练数据集上用测试数据集预测，准确率和召回率还挺高的！
针对离线训练好的模型做的模型检测有
a. 对整个data划分为train/valid/test，训练完成后拿test做离线评估，效果很好
    拿data的更多数据做离线评估，效果依然很好
b. 拿离线模型，在全新的数据集上做验证，效果很差很差
c. 拿离线模型，和data的head -n N或tail -n N份数据做离线模型评估，效果依然很差很差

估计是criteo.py处理data特征导致的，不然为啥训练的模型智能在训练之前的数据上怎么验证都行，
换了数据却不行呢？？？

1. 尝试用训练的方式去预测离线模型？

初步预测是model save/load的问题，即 训练后存储的模型没有被评估时候正确的加载。
https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-model-for-inference
但是，如果是模型加载的问题，那为什么评估的时候脚本load模型能够对训练数据进行正确评估预测呢？这就说明load模型
是没有问题的。
经过反复试验，且试验了load_state_dict这种官网推荐的加载模型方式，依然没用。
反复试验只有使用原来的数据才能进行准确评估，所以一切的问题都指向criteo.py处理数据的方式，
尤其是        feat_mapper, defaults = self.__get_feat_mapper(path)
有问题，因为原始的criteo数据的稀疏特征是编码了的，猜测这里是用索引编号来解码，所以训练的模型仅仅是对原始的
数据有效果，对新提供的数据是没有效果的，即使用原始的数据重新cache一次都不行，因为别忘了，我们用了random_split。

1. 解决了训练数据和此框架模型的顺序不对的问题，虽然拿新的测试数据用离线模型评测精确率和召回率不是0了，
但是依然只有20%左右，咋回事呢？
2. 然后拿https://deepctr-doc.readthedocs.io/en/latest/Quick-Start.html 框架去跑，发现依然有这个问题，
所以突然怀疑是正负样本不均衡的问题导致的！！
可以去google搜索一下：
    pytorch 类别不均衡
    tensorflow 类别不均衡
都有相应的解决办法。
所以，应该是这个问题导致的，否则为什么训练数据集上的效果很高，但是到了新数据集上效果就很差了呢？



